{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Web Scraping</u>\n",
    "\n",
    "## <u>Part \\#1: Scraping the Fremd Webpage</u>\n",
    "\n",
    "In this notebook we will look at 2 different ways of using Python to gain access to an HTML page (web page) in order to find information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Method \\#1:  Exploring Webpages Using the 'requests' Library</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#1:</u>** What is the *requests* library used for?\n",
    "\n",
    "*Note: In order to answer this question, you will need to read the first page of the documentation found at the following link:  https://pypi.python.org/pypi/requests/*\n",
    "\n",
    "**<u>Your Answer:</u>** It allows me to send http requests which I think are similiar to me searching on google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know what the *requests* library is used for, we will it to get the data from the Fremd Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Wikipedia Fremd page, store in the variable req\n",
    "req = requests.get(\"https://en.wikipedia.org/wiki/William_Fremd_High_School\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#2</u>**: Print the value of *req* to see what data is stored in this variable. Then use the *type* method to print the data type stored in *req*. What do you see from the output of these two print statements?\n",
    "\n",
    "**<u>Your Answer:</u>** That there are 200 request.model.Response on the https://en.wikipedia.org/wiki/William_Fremd_High_School."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your first print statement here to print value of 'req':\n",
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your second print statement here to print the type of data 'req' holds:\n",
    "type(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#3:</u>** Look at the directory of req by typing in *dir(req)*.  What do you think this directory shows you?\n",
    "\n",
    "**<u>Your Answer:</u>** I think that dir gives you the methods of req."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__attrs__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_content',\n",
       " '_content_consumed',\n",
       " '_next',\n",
       " 'apparent_encoding',\n",
       " 'close',\n",
       " 'connection',\n",
       " 'content',\n",
       " 'cookies',\n",
       " 'elapsed',\n",
       " 'encoding',\n",
       " 'headers',\n",
       " 'history',\n",
       " 'is_permanent_redirect',\n",
       " 'is_redirect',\n",
       " 'iter_content',\n",
       " 'iter_lines',\n",
       " 'json',\n",
       " 'links',\n",
       " 'next',\n",
       " 'ok',\n",
       " 'raise_for_status',\n",
       " 'raw',\n",
       " 'reason',\n",
       " 'request',\n",
       " 'status_code',\n",
       " 'text',\n",
       " 'url']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#4:</u>**  Add a print statement to the cell below to look at the actual webpage text. Do you see some familiar text from the work we did with HTML/CSS/Javascript first semester?  List 3 or 4 things you can pick out from the text that look familiar to you:\n",
    "\n",
    "**<u>Your Answer:</u>** This shows the code of the website. Like how we learned that we send a request and then we recieve the webpage code. Then we display it. Instead here we just get the code. I can see things like script tags, links, and classes. If you go the actual site and view the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>William Fremd High School - Wikipedia</title>\\n<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"602bf110-342c-4229-b3f1-4d563d83248c\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"William_Fremd_High_School\",\"wgTitle\":\"William Fremd High School\",\"wgCurRevisionId\":1083479842,\"wgRevisionId\":1083479842,\"wgArticleId\":1258351,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"CS1 errors: generic name\",\"CS1 errors: URL\",\"All articles with dead external links\",\"Articles with dead external link'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_page=req.text\n",
    "\n",
    "# print the value of w_page here\n",
    "w_page[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Task \\#1:</u>** Use the *requests* library again, but this time get the data from the actual FHS webpage, *http://fhs.d211.org/*. Store this data in the variable *req2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the FHS page, http://fhs.d211.org/, and store as req2\n",
    "# HINT: There is useful code in the second cell!\n",
    "req2 = requests.get(\"http://fhs.d211.org/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AP test, you learned the names of the various pieces of the URL http://fhs.d211.org. Here they are:\n",
    "\n",
    "* *.org*: top-level domain \n",
    "  * can be .com, .org, .net, and many more\n",
    "  \n",
    "  \n",
    "* *d211*: second-level domain \n",
    "  * a second-level domain must be registered\n",
    "  * the d211 second-level domain is unique to District 211 webpages\n",
    "  \n",
    "  \n",
    "* *fhs*: subdomain \n",
    "  * fhs is subdomain of d211\n",
    "  * this structure reflects the fact that Fremd is a part of District 211\n",
    "  \n",
    "  \n",
    "* *http*: the protocol for data exchange\n",
    "  * you learned a lot about this protocol last semester\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Metadata from the Fremd Webpage </u>\n",
    "\n",
    "We can look at information about the FHS web page (metadata) by accessing the headers property of the Response object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\r\\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Frameset//EN\" \"http://www.w3.org/TR/html4/frameset.dtd\">\\r\\n\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n    <title>Fremd HS / Homepage</title>\\r\\n    <!--\\r\\n    <PageMap>\\r\\n    <DataObject type=\"document\">\\r\\n    <Attribute name=\"siteid\">9</Attribute>\\r\\n    </DataObject>\\r\\n    </PageMap>\\r\\n    -->\\r\\n\\r\\n    \\r\\n    <meta property=\"og:type\" content=\"website\" />\\r\\n<meta property=\"fb:app_id\" content=\"411584262324304\" />\\r\\n<meta property=\"og:url\" content=\"http%3A%2F%2Fadc.d211.org%2Fsite%2Fdefault.aspx%3FDomainID%3D9\" />\\r\\n<meta property=\"og:title\" content=\"Fremd HS / Homepage\" />\\r\\n<meta name=\"twitter:card\" value=\"summary\" />\\r\\n<meta name=\"twitter:title\" content=\"Fremd HS / Homepage\" />\\r\\n<meta itemprop=\"name\" content=\"Fremd HS / Homepage\" />\\r\\n\\r\\n    <!-- Begin swuc.GlobalJS -->\\r\\n<script type=\"text/javascript\">\\r\\n staticURL = \"https://adc.d211.org/Static/\";\\r\\n SessionTimeout = \"50\";\\r\\n BBHelpURL = \"\";\\r\\n</script>\\r\\n<!-- End swuc.GlobalJS -->\\r\\n\\r\\n    <script src=\\'https://adc.d211.org/S'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /r/n show line breaks I think\n",
    "# Also if you do ctr + i you get different results than crt + u. The text you get from the request seems to come from ctr + u.\n",
    "# My only reason I can think of is that js isn't loaded?\n",
    "req2.text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '392699', 'Connection': 'keep-alive', 'Date': 'Mon, 23 May 2022 03:43:37 GMT', 'Cache-Control': 'no-cache, no-store', 'Pragma': 'no-cache', 'Expires': '-1', 'Server': 'Microsoft-IIS/8.5', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains;', 'X-XSS-Protection': '1; mode=block', 'X-AspNet-Version': '4.0.30319', 'Set-Cookie': 'PSN=+IsCigvKEHFzYB1hRU3cjA==; path=/; secure; HttpOnly, PSDB=get+ikDKUSgz5GSCEtbxNpOV6Ak/U0I1RXwREP4/87E=; path=/; secure; HttpOnly, CSAN=46imUsew8wdbkuBsFQu0pQ==; path=/; secure; HttpOnly, AccountID=Xogon24LhVEF1Gfd40nUZQ==; path=/; secure; HttpOnly, APIKey=6bbe9abb-2ca5-42ca-ac9c-a4a52d8c9ccb; path=/; secure; HttpOnly, SWSessionID=96197a67-3996-49d6-9220-bb884131fe18; path=/; secure; HttpOnly, RedirectTo=http%3A%2F%2Fadc.d211.org%2Fsite%2Fdefault.aspx%3FDomainID%3D9; path=/; secure, CancelRedirectTo=; expires=Sun, 22-May-2022 19:43:37 GMT; path=/; secure', 'X-Powered-By': 'ASP.NET', 'Content-Security-Policy': \"frame-ancestors 'self' https://*.ally.ac;\", 'X-Frame-Options': 'SAMEORIGIN', 'X-Cache': 'Miss from cloudfront', 'Via': '1.1 4cbb89cd343b8f6e6698aa5a9e2ca87e.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'ORD51-C4', 'X-Amz-Cf-Id': 'HsowRPEdxcXQ2PlvmnfzEdaNCWzueMjtH-ylNgkBY3yiET1mBtQBTg=='}\n"
     ]
    }
   ],
   "source": [
    "print(req2.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#5:</u>**  What do you see in the metadata above? What URLs can find in these headers? Can you learn anything about these URLs by searching Google? \n",
    "\n",
    "**<u>Your Answer:</u>** I don't really see urls but I do see something called cloudfront. Which when I searched tells me it's a content delivery network by amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Data from the Fremd Webpage</u> \n",
    "\n",
    "Files are comprised of data and metadata (data about the data). You saw the metadata for the Fremd webpage above. Now here's the main data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Frameset//EN\" \"http://www.w3.org/TR/html4/frameset.dtd\">\r\n",
      "\r\n",
      "<html lang=\"en\">\r\n",
      "<head>\r\n",
      "    <title>Fremd HS / Homepage</title>\r\n",
      "    <!--\r\n",
      "    <PageMap>\r\n",
      "    <DataObject type=\"document\">\r\n",
      "    <Attribute name=\"siteid\">9</Attribute>\r\n",
      "    </DataObject>\r\n",
      "    </PageMap>\r\n",
      "    -->\r\n",
      "\r\n",
      "    \r\n",
      "    <meta property=\"og:type\" content=\"website\" />\r\n",
      "<meta property=\"fb:app_id\" content=\"411584262324304\" />\r\n",
      "<meta property=\"og:url\" content=\"http%3A%2F%2Fadc.d211.org%2Fsite%2Fdefault.aspx%3FDomainID%3D9\" />\r\n",
      "<meta property=\"og:title\" content=\"Fremd HS / Homepage\" />\r\n",
      "<meta name=\"twitter:card\" value=\"summary\" />\r\n",
      "<meta name=\"twitter:title\" content=\"Fremd HS / Homepage\" />\r\n",
      "<meta itemprop=\"name\" content=\"Fremd HS / Homepage\" />\r\n",
      "\r\n",
      "    <!-- Begin swuc.GlobalJS -->\r\n",
      "<script type=\"text/javascript\">\r\n",
      " staticURL = \"https://adc.d211.org/Static/\";\r\n",
      " SessionTimeout = \"50\";\r\n",
      " BBHelpURL = \"\";\r\n",
      "</script>\r\n",
      "<!-- End swuc.GlobalJS -->\r\n",
      "\r\n",
      "    <script src='https://adc.d211.org/S\n"
     ]
    }
   ],
   "source": [
    "fhs_page = req2.text   # Save the text of the webpage in a variable\n",
    "# Since I didn't use print before it gave me in raw text form with /r and /n I think. \n",
    "print(fhs_page[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#6:</u>**  What do you see in the output above? What is the type of data stored in fhs_page? \n",
    "\n",
    "*Note: Use the *type* method to answer the second part of this question.*\n",
    "\n",
    "**<u>Your Answer:</u>** It return the code of the site as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here to print the type of data 'fhs_page' holds:\n",
    "type(fhs_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find specific instances of HTML tags in fhs_page we would now need to use methods of the string object. While this can be done, there is a better and more efficient way to traverse our way through a web page.  String manipulation alone often involves the use of regular expressions (and the Python *re* module). \n",
    "\n",
    "Regular expressions are used in many different programming languages (including Javascript). Regular expressions are very useful, but can also get quite complicated when used properly.  You will see an example of using regular expressions and the *re* module later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#7:</u>**  What is a \"regular expression\" and what is it used for?  \n",
    "\n",
    "*Note: You will need to refer to https://docs.python.org/3/howto/regex.html#regex-howto for more information about regular expressions.*\n",
    "\n",
    "**<u>Your Answer:</u>** It matches certain patterns of text. I used it for my pt project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at a second way we can gain access to HTML pages for manipulation. This is a more elegant (and much simpler) way to access different parts of a web page than using the built-in Requests library:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Method \\#2:  Exploring Webpages Using the Beautiful Soup Library</u>\n",
    "\n",
    "A library for easily getting data out of HTML and XML files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#8:</u>** Visit the Beautiful Soup documentation at this link:  https://www.crummy.com/software/BeautifulSoup/. What are the three features that make Beautiful Soup so powerful?\n",
    "\n",
    "**<u>Your Answer:</u>** \n",
    "1. Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a parse tree: a toolkit for dissecting a document and extracting what you need. It doesn't take much code to write an application\n",
    "2. Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8. You don't have to think about encodings, unless the document doesn't specify an encoding and Beautiful Soup can't detect one. Then you just have to specify the original encoding.\n",
    "3. Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # Import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use Beautiful Soup to parse a web page document. To get a web page into our notebook we can either have BS4 read in an html file from our root directory or, in this case, we can just use the string we created earlier when we opened the FHS page using the Requests library (stored in fhsPage):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#9:</u>** Add a print statement to the code below. What similarities do you notice with *print(fhs_page)* from earlier?\n",
    "\n",
    "**<u>Your Answer:</u>** It still looks very similar to the previous string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Frameset//EN\" \"http://www.w3.org/TR/html4/frameset.dtd\">\r\n",
      "\r\n",
      "<html lang=\"en\">\r\n",
      "<head>\r\n",
      "    <title>Fremd HS / Homepage</title>\r\n",
      "    <!--\r\n",
      "    <PageMap>\r\n",
      "    <DataObject type=\"document\">\r\n",
      "    <Attribute name=\"siteid\">9</Attribute>\r\n",
      "    </DataObject>\r\n",
      "    </PageMap>\r\n",
      "    -->\r\n",
      "\r\n",
      "    \r\n",
      "    <meta property=\"og:type\" content=\"website\" />\r\n",
      "<meta property=\"fb:app_id\" content=\"411584262324304\" />\r\n",
      "<meta property=\"og:url\" content=\"http%3A%2F%2Fadc.d211.org%2Fsite%2Fdefault.aspx%3FDomainID%3D9\" />\r\n",
      "<meta property=\"og:title\" content=\"Fremd HS / Homepage\" />\r\n",
      "<meta name=\"twitter:card\" value=\"summary\" />\r\n",
      "<meta name=\"twitter:title\" content=\"Fremd HS / Homepage\" />\r\n",
      "<meta itemprop=\"name\" content=\"Fremd HS / Homepage\" />\r\n",
      "\r\n",
      "    <!-- Begin swuc.GlobalJS -->\r\n",
      "<script type=\"text/javascript\">\r\n",
      " staticURL = \"https://adc.d211.org/Static/\";\r\n",
      " SessionTimeout = \"50\";\r\n",
      " BBHelpURL = \"\";\r\n",
      "</script>\r\n",
      "<!-- End swuc.GlobalJS -->\r\n",
      "\r\n",
      "    <script src='https://adc.d211.org/S\n"
     ]
    }
   ],
   "source": [
    "fhs_soup = BeautifulSoup(fhs_page, 'html.parser')   # Beautiful Soup will allow you to pass in an HTML page as a string\n",
    "\n",
    "# Print the contents of 'fhs_soup' to see what it looks like\n",
    "print(fhs_page[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Question \\#10:</u>** What data type is stored in *fhs_soup*? You will need to write code in the cell below to answer this question.\n",
    "\n",
    "**<u>Your Answer:</u>** It is a bs4.BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here to print they type of data 'fhs_soup' is holding:\n",
    "type(fhs_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Task \\#2:</u>** Now we will look at some of the properties and methods of the BeautifulSoup object.  For each one, write a code comment explaining what you think the method does (or what the property tells us)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Frameset//EN\" \"http://www.w3.org/TR/html4/frameset.dtd\">\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   Fremd HS / Homepage\n",
      "  </title>\n",
      "  <!--\r\n",
      "    <PageMap>\r\n",
      "    <DataObject type=\"document\">\r\n",
      "    <Attribute name=\"siteid\">9</Attribute>\r\n",
      "    </DataObject>\r\n",
      "    </PageMap>\r\n",
      "    -->\n",
      "  <meta content=\"website\" property=\"og:type\"/>\n",
      "  <meta content=\"411584262324304\" property=\"fb:app_id\"/>\n",
      "  <meta content=\"http%3A%2F%2Fadc.d211.org%2Fsite%2Fdefault.aspx%3FDomainID%3D9\" property=\"og:url\"/>\n",
      "  <meta content=\"Fremd HS / Homepage\" property=\"og:title\"/>\n",
      "  <meta name=\"twitter:card\" value=\"summary\"/>\n",
      "  <meta content=\"Fremd HS / Homepage\" name=\"twitter:title\"/>\n",
      "  <meta content=\"Fremd HS / Homepage\" itemprop=\"name\"/>\n",
      "  <!-- Begin swuc.GlobalJS -->\n",
      "  <script type=\"text/javascript\">\n",
      "   staticURL = \"https://adc.d211.org/Static/\";\r\n",
      " SessionTimeout = \"50\";\r\n",
      " BBHelpURL = \"\";\n",
      "  </script>\n",
      "  <!-- End swuc.GlobalJS -->\n",
      "  <script src=\"https://adc.d211.org/Static/GlobalAssets/Scrip\n"
     ]
    }
   ],
   "source": [
    "print(fhs_soup.prettify()[:1000])   # I think it seperates the tags and makes the code easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Fremd HS / Homepage</title>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhs_soup.title  # This gets me the title tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>Home of the Vikings</p>, <p class=\"ui-article-description\">\n",
      "<span class=\"sw-calendar-block-time\">8:30 AM</span>\n",
      "<span class=\"sw-calendar-block-title\"><a href=\"\r\n",
      "https://adc.d211.org/site/Default.aspx?PageID=12&amp;DomainID=9#calendar8/20220523/event/14277\">Senior Breakfast</a></span>\n",
      "</p>, <p class=\"ui-article-description\">\n",
      "<span class=\"sw-calendar-block-time\">7:30 PM</span>\n",
      "<span class=\"sw-calendar-block-title\"><a href=\"\r\n",
      "https://adc.d211.org/site/Default.aspx?PageID=12&amp;DomainID=9#calendar8/20220523/event/13556\">Graduation</a></span>\n",
      "</p>, <p class=\"ui-article-description\">\n",
      "<span class=\"sw-calendar-block-title\"><a href=\"\r\n",
      "https://adc.d211.org/site/Default.aspx?PageID=12&amp;DomainID=9#calendar8/20220525/event/14121\">Final Exams</a></span>\n",
      "</p>, <p class=\"ui-article-description\">\n",
      "<span class=\"sw-calendar-block-title\"><a href=\"\r\n",
      "https://adc.d211.org/site/Default.aspx?PageID=12&amp;DomainID=9#calendar8/20220526/event/14122\">Final Exams</a></span>\n",
      "</p>]\n"
     ]
    }
   ],
   "source": [
    "len(fhs_soup.find_all(\"p\"))  # It has an array of all the paragrpah tags.\n",
    "print(fhs_soup.find_all(\"p\")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Home of the Vikings</p>\n"
     ]
    }
   ],
   "source": [
    "# Write the code to see what is contained in all <p> tags\n",
    "    # HINT: Use the 'find_all' method above to find all \"p\" tags (this creates a list of <p> tags) and store \n",
    "    #       what it returns in a variable. Then loop through each tag in the list and print each one individually\n",
    "p_tags = fhs_soup.find_all(\"p\")\n",
    "for p in p_tags:\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Home of the Vikings</p>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhs_soup.p  # This just gets 1 paragraph tag and stops like queryselector. It finds the first paragraph tag it can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'website'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhs_soup.meta[\"content\"]  # It finds the specific tag then it displays what the attribute is.\n",
    "                          # <meta property=\"og:type\" content=\"website\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['website',\n",
       " '411584262324304',\n",
       " 'http%3A%2F%2Fadc.d211.org%2Fsite%2Fdefault.aspx%3FDomainID%3D9',\n",
       " 'Fremd HS / Homepage',\n",
       " 'Fremd HS / Homepage',\n",
       " 'Fremd HS / Homepage',\n",
       " 'width=device-width, initial-scale=1.0']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t[\"content\"] for t in fhs_soup.find_all(\"meta\") if t.get(\"content\")]  # Make a list of 'content' for each <meta> tag\n",
    "\n",
    "#for t in fhs_soup.find_all(\"meta\"):\n",
    "#    print(t.get(\"content\"))\n",
    "#    #print(t[\"content\"])\n",
    "\n",
    "# Go through all the meta tags and if there is an attribute of 'content' then add t['content'] to the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sw-skipnav\" href=\"#sw-maincontent\" id=\"skipLink\" tabindex=\"0\">Skip to Main Content</a>,\n",
       " <a alt=\"District Home\" href=\"https://adc.d211.org/Domain/4\" tabindex=\"0\" title=\"Return to the homepage on the district site.\"><span>District Home<div id=\"sw-home-icon\"></div>\n",
       " </span></a>,\n",
       " <a href=\"/Domain/8\">Palatine HS</a>,\n",
       " <a href=\"/Domain/9\">Fremd HS</a>,\n",
       " <a href=\"/Domain/10\">Conant HS</a>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhs_soup.find_all(\"a\")[:5]  # Gets all link tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # This is the regular expressions module that lets you check if a string matches a general format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Athletics Calendar'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhs_soup.find_all(string=re.compile(\"Calendar\"))[1]\n",
    "#fhs_soup.find_all(string=re.compile('Calendar'))[3]\n",
    "# It finds the string calendar then adds everythign in between the tags it's between to the array\n",
    "# <a class='view-calendar-link' href=\"/Page/12\"><span>View Calendar</span></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fhs_soup.find_all(string=re.compile(\"Calendar\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**<u>Task \\#3:</u>** Now find a school-appropriate webpage that you visit often.  Read it in using the *Requests* library and then use *Beautiful Soup* to find all instances of two of the following tags:  *hyperlink*, *list*, *paragraph*, *style*, or another of your choice.  Be sure to comment your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <!DOCTYPE html>\n",
      "    <html lang=\"en-US\">\n",
      "      <head>\n",
      "        <script>\n",
      "    var __SUPPORTS_TIMING_API = typeof performance === 'object' && !!performance.mark && !! performance.measure && !!performance.getEntriesByType;\n",
      "    function __perfMark(name) { __SUPPORTS_TIMING_API && performance.mark(name); };\n",
      "    var __firstPostLoaded = false;\n",
      "    function __markFirstPostVisible() {\n",
      "      if (__firstPostLoaded) { return; }\n",
      "      __firstPostLoaded = true;\n",
      "      __perfMark(\"first_post_title_image_loaded\");\n",
      "    }\n",
      "    var __firstCommentLoaded = false;\n",
      "    function __markFirstCommentVisible() {\n",
      "      if (__firstCommentLoaded) { return; }\n",
      "      __firstCommentLoaded = true;\n",
      "      __perfMark(\"first_comment_loaded\");\n",
      "    }\n",
      "  </script>\n",
      "        <script>__perfMark('head_tag_start');</script>\n",
      "        <meta charSet=\"utf-8\"/>\n",
      "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "        <meta name=\"referrer\" content=\"origin-when-cross-origin\" />\n",
      "        <style>\n",
      "  /* http://meyerwe\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en-US\">\n",
      " <head>\n",
      "  <script>\n",
      "   var __SUPPORTS_TIMING_API = typeof performance === 'object' && !!performance.mark && !! performance.measure && !!performance.getEntriesByType;\n",
      "    function __perfMark(name) { __SUPPORTS_TIMING_API && performance.mark(name); };\n",
      "    var __firstPostLoaded = false;\n",
      "    function __markFirstPostVisible() {\n",
      "      if (__firstPostLoaded) { return; }\n",
      "      __firstPostLoaded = true;\n",
      "      __perfMark(\"first_post_title_image_loaded\");\n",
      "    }\n",
      "    var __firstCommentLoaded = false;\n",
      "    function __markFirstCommentVisible() {\n",
      "      if (__firstCommentLoaded) { return; }\n",
      "      __firstCommentLoaded = true;\n",
      "      __perfMark(\"first_comment_loaded\");\n",
      "    }\n",
      "  </script>\n",
      "  <script>\n",
      "   __perfMark('head_tag_start');\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n",
      "  <style>\n",
      "   /* http://meyerweb.com/eric/tools/css/reset/\n",
      "    v2.0 | 201101\n"
     ]
    }
   ],
   "source": [
    "# Import Required Module\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "  \n",
    "# Web URL\n",
    "Web_url = \"https://www.reddit.com\"\n",
    "  \n",
    "# Get URL Content\n",
    "r = requests.get(Web_url)\n",
    "print(r.text[:1000])\n",
    "# Parse HTML Code\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"_3Wg53T10KuuPmyWOMWsY2F _2iuoyPiKHN3kfOoeIQalDT _2tU8R9NTqhvBrhoNAXWWcP HNozj_dKjQZ59ZsfEegz8 _2nelDm85zKKmuD94NequP0\" href=\"https://www.reddit.com/login/?dest=https%3A%2F%2Fwww.reddit.com%2F\" role=\"button\" tabindex=\"0\">Log In</a>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')[2]\n",
    "# The reason it's so long is because the code was all on one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"_3Wg53T10KuuPmyWOMWsY2F _2iuoyPiKHN3kfOoeIQalDT _2tU8R9NTqhvBrhoNAXWWcP HNozj_dKjQZ59ZsfEegz8 _2nelDm85zKKmuD94NequP0\" href=\"https://www.reddit.com/login/?dest=https%3A%2F%2Fwww.reddit.com%2F\" role=\"button\" tabindex=\"0\">Log In</a>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a', text = re.compile('Log In'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"_1qeIAgB0cPwnLhDF9XSiJM\">I'm almost 30 it's getting to the point where I'm getting older and I'm still learning.</p>,\n",
       " <p class=\"_1qeIAgB0cPwnLhDF9XSiJM\">For example I'm taking voice lessons from someone who's about 10 years younger than me.</p>,\n",
       " <p class=\"_1qeIAgB0cPwnLhDF9XSiJM\">I remember how my parents acted when being taught something, or shown something, they would just write it off as something the \"kids\" can deal with, and unimportant.</p>,\n",
       " <p class=\"_1qeIAgB0cPwnLhDF9XSiJM\">I'm doing my best not to do this to other people as I grow up as it leaves the older person unable to function, and the younger person frustrated enough to want to jump through a window.</p>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I were to webscrape reddit on my computer, when I send a request would it respond with a reddit page on my account since I'm signed into my account. Or would it be as if I was in incognito."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
